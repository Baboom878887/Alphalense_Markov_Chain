{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Analysis for LEAP Option Price Prediction\n",
    "\n",
    "This notebook explores using Markov Chains to predict the day-to-day movement of LEAP (Long-term Equity Anticipation Securities) option prices using **real option data from QuantConnect**.\n",
    "\n",
    "## LEAP Option Definition\n",
    "A LEAP option is defined as:\n",
    "- An **at-the-money (ATM)** option (within 5% of underlying price)\n",
    "- With **more than one year (>365 days)** until expiration\n",
    "- The option **closest to 365 days** to expiration in the option chain\n",
    "\n",
    "## Data Sources\n",
    "- **Option Prices**: QuantConnect historical option chain data\n",
    "- **Greeks**: Delta, Gamma, Vega, Theta, Rho provided by QuantConnect API (not calculated)\n",
    "- **Implied Volatility**: From QuantConnect option chain\n",
    "- **Contract Filtering**: Limited to LEAP options matching our criteria to minimize data overhead\n",
    "\n",
    "## Methodology\n",
    "1. **Data Collection**: Pull historical LEAP option data from QuantConnect for selected symbols\n",
    "2. **LEAP Selection**: Filter option chains to identify LEAP options matching our criteria\n",
    "3. **State Definition**: Define discrete states based on option price movements (Up, Down, Flat)\n",
    "4. **Transition Matrix**: Build a transition probability matrix from historical data\n",
    "5. **Prediction & Alpha Analysis**: Evaluate if Markov Chain predictions have any predictive power (alpha)\n",
    "6. **Greeks Analysis**: Examine how Greeks correlate with state transitions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from io import StringIO\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "qb = QuantBook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Markov Chain Helper Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovChainAnalyzer:\n",
    "    \"\"\"\n",
    "    A class to analyze price movements using Markov Chains.\n",
    "    \n",
    "    States are defined based on daily returns:\n",
    "    - 'Up': Daily return > threshold\n",
    "    - 'Down': Daily return < -threshold  \n",
    "    - 'Flat': Daily return within [-threshold, threshold]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, threshold=0.01):\n",
    "        \"\"\"\n",
    "        Initialize the Markov Chain Analyzer.\n",
    "        \n",
    "        Args:\n",
    "            threshold: The return threshold to define Up/Down/Flat states (default 1%)\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.states = ['Down', 'Flat', 'Up']\n",
    "        self.transition_matrix = None\n",
    "        self.state_counts = None\n",
    "        \n",
    "    def returns_to_states(self, returns):\n",
    "        \"\"\"\n",
    "        Convert a series of returns to discrete states.\n",
    "        \n",
    "        Args:\n",
    "            returns: pd.Series of daily returns\n",
    "            \n",
    "        Returns:\n",
    "            pd.Series of state labels\n",
    "        \"\"\"\n",
    "        conditions = [\n",
    "            returns < -self.threshold,\n",
    "            returns > self.threshold\n",
    "        ]\n",
    "        choices = ['Down', 'Up']\n",
    "        states = np.select(conditions, choices, default='Flat')\n",
    "        return pd.Series(states, index=returns.index)\n",
    "    \n",
    "    def build_transition_matrix(self, states):\n",
    "        \"\"\"\n",
    "        Build a transition probability matrix from a sequence of states.\n",
    "        \n",
    "        Args:\n",
    "            states: pd.Series of state labels\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame representing the transition probability matrix\n",
    "        \"\"\"\n",
    "        # Initialize counts matrix\n",
    "        state_list = self.states\n",
    "        n_states = len(state_list)\n",
    "        counts = pd.DataFrame(\n",
    "            np.zeros((n_states, n_states)),\n",
    "            index=state_list,\n",
    "            columns=state_list\n",
    "        )\n",
    "        \n",
    "        # Count transitions (vectorized approach)\n",
    "        current_states = states.iloc[:-1].values\n",
    "        next_states = states.iloc[1:].values\n",
    "        \n",
    "        for i, curr in enumerate(current_states):\n",
    "            next_s = next_states[i]\n",
    "            counts.loc[curr, next_s] += 1\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        self.state_counts = counts.copy()\n",
    "        row_sums = counts.sum(axis=1)\n",
    "        self.transition_matrix = counts.div(row_sums, axis=0).fillna(0)\n",
    "        \n",
    "        return self.transition_matrix\n",
    "    \n",
    "    def predict_next_state(self, current_state):\n",
    "        \"\"\"\n",
    "        Predict the most likely next state given the current state.\n",
    "        \n",
    "        Args:\n",
    "            current_state: The current state ('Up', 'Down', or 'Flat')\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (predicted_state, probability)\n",
    "        \"\"\"\n",
    "        if self.transition_matrix is None:\n",
    "            raise ValueError(\"Transition matrix not built. Call build_transition_matrix first.\")\n",
    "        \n",
    "        probs = self.transition_matrix.loc[current_state]\n",
    "        predicted_state = probs.idxmax()\n",
    "        probability = probs.max()\n",
    "        \n",
    "        return predicted_state, probability\n",
    "    \n",
    "    def calculate_stationary_distribution(self):\n",
    "        \"\"\"\n",
    "        Calculate the stationary distribution of the Markov Chain.\n",
    "        \n",
    "        Returns:\n",
    "            pd.Series representing the stationary distribution\n",
    "        \"\"\"\n",
    "        if self.transition_matrix is None:\n",
    "            raise ValueError(\"Transition matrix not built. Call build_transition_matrix first.\")\n",
    "        \n",
    "        # Solve for stationary distribution: pi * P = pi\n",
    "        P = self.transition_matrix.values.T\n",
    "        n = P.shape[0]\n",
    "        \n",
    "        # Set up the system (P^T - I)pi = 0 with sum(pi) = 1\n",
    "        A = np.vstack([P - np.eye(n), np.ones(n)])\n",
    "        b = np.zeros(n + 1)\n",
    "        b[-1] = 1\n",
    "        \n",
    "        # Solve using least squares\n",
    "        pi, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "        \n",
    "        return pd.Series(pi, index=self.states)\n",
    "    \n",
    "    def backtest_predictions(self, returns, train_ratio=0.7):\n",
    "        \"\"\"\n",
    "        Backtest the Markov Chain predictions.\n",
    "        \n",
    "        Args:\n",
    "            returns: pd.Series of daily returns\n",
    "            train_ratio: Ratio of data to use for training (default 0.7)\n",
    "            \n",
    "        Returns:\n",
    "            dict: Backtest results including accuracy, predictions DataFrame\n",
    "        \"\"\"\n",
    "        # Convert to states\n",
    "        states = self.returns_to_states(returns)\n",
    "        \n",
    "        # Split into train/test\n",
    "        split_idx = int(len(states) * train_ratio)\n",
    "        train_states = states.iloc[:split_idx]\n",
    "        test_states = states.iloc[split_idx:]\n",
    "        \n",
    "        # Build transition matrix on training data\n",
    "        self.build_transition_matrix(train_states)\n",
    "        \n",
    "        # Make predictions on test data\n",
    "        predictions = []\n",
    "        actual = []\n",
    "        \n",
    "        for i in range(len(test_states) - 1):\n",
    "            current = test_states.iloc[i]\n",
    "            predicted, prob = self.predict_next_state(current)\n",
    "            actual_next = test_states.iloc[i + 1]\n",
    "            \n",
    "            predictions.append({\n",
    "                'date': test_states.index[i + 1],\n",
    "                'current_state': current,\n",
    "                'predicted_state': predicted,\n",
    "                'actual_state': actual_next,\n",
    "                'probability': prob,\n",
    "                'correct': predicted == actual_next\n",
    "            })\n",
    "        \n",
    "        results_df = pd.DataFrame(predictions)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = results_df['correct'].mean()\n",
    "        \n",
    "        # Calculate accuracy by state\n",
    "        accuracy_by_state = results_df.groupby('current_state')['correct'].mean()\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'accuracy_by_state': accuracy_by_state,\n",
    "            'predictions_df': results_df,\n",
    "            'transition_matrix': self.transition_matrix,\n",
    "            'n_train': len(train_states),\n",
    "            'n_test': len(test_states)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: LEAP Option Selection Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dte(expiry_date, reference_date):\n",
    "    \"\"\"\n",
    "    Calculate days to expiration.\n",
    "    \n",
    "    Args:\n",
    "        expiry_date: Option expiration date\n",
    "        reference_date: Reference date for calculation\n",
    "        \n",
    "    Returns:\n",
    "        int: Days to expiration\n",
    "    \"\"\"\n",
    "    return (expiry_date - reference_date).days\n",
    "\n",
    "\n",
    "def select_leap_option(option_chain, underlying_price, reference_date, target_dte=365):\n",
    "    \"\"\"\n",
    "    Select the LEAP option from an option chain based on our criteria:\n",
    "    - At-the-money (ATM)\n",
    "    - More than 365 days to expiration\n",
    "    - Closest to 365 days to expiration\n",
    "    \n",
    "    Args:\n",
    "        option_chain: QuantConnect OptionChain object from the option chain API\n",
    "        underlying_price: Current price of the underlying asset\n",
    "        reference_date: The reference date for calculating days to expiration\n",
    "        target_dte: Target days to expiration (default 365)\n",
    "        \n",
    "    Returns:\n",
    "        Selected option contract or None if no valid LEAP found\n",
    "    \"\"\"\n",
    "    if option_chain is None or len(list(option_chain)) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Convert to list for easier filtering\n",
    "    contracts = list(option_chain)\n",
    "    \n",
    "    # Filter for options with DTE > 365 (LEAP requirement)\n",
    "    leap_options = [x for x in contracts if calculate_dte(x.Expiry, reference_date) > target_dte]\n",
    "    \n",
    "    if len(leap_options) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Filter for at-the-money options (within 5% of underlying price)\n",
    "    atm_tolerance = 0.05\n",
    "    atm_options = [\n",
    "        x for x in leap_options \n",
    "        if abs(x.Strike - underlying_price) / underlying_price <= atm_tolerance\n",
    "    ]\n",
    "    \n",
    "    if len(atm_options) == 0:\n",
    "        # If no options within 5%, find closest to ATM\n",
    "        atm_options = sorted(leap_options, key=lambda x: abs(x.Strike - underlying_price))[:5]\n",
    "    \n",
    "    # Select the option closest to target_dte days to expiration\n",
    "    selected = min(\n",
    "        atm_options,\n",
    "        key=lambda x: abs(calculate_dte(x.Expiry, reference_date) - target_dte)\n",
    "    )\n",
    "    \n",
    "    return selected\n",
    "\n",
    "\n",
    "def get_leap_option_history(qb, symbol, start_date, end_date, option_type='call', target_dte=365):\n",
    "    \"\"\"\n",
    "    Get historical data for LEAP options using QuantConnect's option data.\n",
    "    \n",
    "    Args:\n",
    "        qb: QuantBook instance\n",
    "        symbol: Underlying symbol string (e.g., 'SPY')\n",
    "        start_date: Start date for analysis\n",
    "        end_date: End date for analysis\n",
    "        option_type: 'call' or 'put'\n",
    "        target_dte: Target days to expiration for LEAP (default 365)\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame with LEAP option price and Greeks history\n",
    "    \"\"\"\n",
    "    # Add underlying equity\n",
    "    equity = qb.AddEquity(symbol, Resolution.Daily)\n",
    "    equity_symbol = equity.Symbol\n",
    "    \n",
    "    # Add option universe for this equity\n",
    "    option = qb.AddOption(symbol, Resolution.Daily)\n",
    "    option.SetFilter(universe => universe.Strikes(-5, +5)\n",
    "                                           .Expiration(timedelta(365), timedelta(730)))\n",
    "    \n",
    "    # Get option chain history\n",
    "    option_history = qb.OptionHistory(equity_symbol, start_date, end_date, Resolution.Daily)\n",
    "    \n",
    "    if option_history.empty:\n",
    "        print(f\"No option history found for {symbol}\")\n",
    "        return None\n",
    "    \n",
    "    # Get equity price history for ATM calculation\n",
    "    equity_history = qb.History(equity_symbol, start_date, end_date, Resolution.Daily)\n",
    "    \n",
    "    if equity_history.empty:\n",
    "        print(f\"No equity history found for {symbol}\")\n",
    "        return None\n",
    "    \n",
    "    # Process each date to find LEAP options\n",
    "    leap_data = []\n",
    "    \n",
    "    for date in option_history.index.get_level_values('time').unique():\n",
    "        # Get equity price for this date\n",
    "        if isinstance(equity_history.index, pd.MultiIndex):\n",
    "            equity_price_data = equity_history.loc[equity_symbol].loc[date]\n",
    "        else:\n",
    "            equity_price_data = equity_history.loc[date]\n",
    "        \n",
    "        underlying_price = equity_price_data['close']\n",
    "        \n",
    "        # Get option chain for this date\n",
    "        chain = option_history.loc[date]\n",
    "        \n",
    "        # Filter by option type (call or put)\n",
    "        if option_type.lower() == 'call':\n",
    "            chain = chain[chain.index.get_level_values('right') == 'Call']\n",
    "        else:\n",
    "            chain = chain[chain.index.get_level_values('right') == 'Put']\n",
    "        \n",
    "        if chain.empty:\n",
    "            continue\n",
    "        \n",
    "        # Find LEAP option for this date using helper function\n",
    "        # Calculate DTE for all options\n",
    "        chain['dte'] = chain.index.get_level_values('expiry').map(lambda exp: calculate_dte(pd.to_datetime(exp), date))\n",
    "        leap_chain = chain[chain['dte'] > target_dte]\n",
    "        \n",
    "        if leap_chain.empty:\n",
    "            continue\n",
    "        \n",
    "        # Filter for ATM (within 5% of underlying)\n",
    "        leap_chain['strike'] = leap_chain.index.get_level_values('strike')\n",
    "        leap_chain['atm_distance'] = abs(leap_chain['strike'] - underlying_price) / underlying_price\n",
    "        atm_leap = leap_chain[leap_chain['atm_distance'] <= 0.05]\n",
    "        \n",
    "        if atm_leap.empty:\n",
    "            # Take closest to ATM\n",
    "            atm_leap = leap_chain.nsmallest(1, 'atm_distance')\n",
    "        \n",
    "        # Select closest to target_dte\n",
    "        atm_leap['dte_distance'] = abs(atm_leap['dte'] - target_dte)\n",
    "        selected = atm_leap.nsmallest(1, 'dte_distance')\n",
    "        \n",
    "        if not selected.empty:\n",
    "            row = selected.iloc[0]\n",
    "            leap_data.append({\n",
    "                'date': date,\n",
    "                'price': row.get('close', np.nan),\n",
    "                'underlying_price': underlying_price,\n",
    "                'strike': row['strike'],\n",
    "                'dte': row['dte'],\n",
    "                'delta': row.get('delta', np.nan),\n",
    "                'gamma': row.get('gamma', np.nan),\n",
    "                'vega': row.get('vega', np.nan),\n",
    "                'theta': row.get('theta', np.nan),\n",
    "                'rho': row.get('rho', np.nan),\n",
    "                'implied_volatility': row.get('impliedvolatility', np.nan),\n",
    "                'open_interest': row.get('openinterest', 0),\n",
    "                'volume': row.get('volume', 0)\n",
    "            })\n",
    "    \n",
    "    if len(leap_data) == 0:\n",
    "        print(f\"No LEAP options found for {symbol}\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.DataFrame(leap_data)\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Setup and Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analysis parameters\n",
    "symbols = ['SPY', 'QQQ', 'IWM', 'AAPL', 'MSFT']  # Major ETFs and stocks with liquid LEAP options\n",
    "start_date = datetime(2018, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "\n",
    "# Markov Chain parameters\n",
    "threshold = 0.01  # 1% threshold for Up/Down classification\n",
    "train_ratio = 0.7  # 70% for training, 30% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect LEAP option price data for each symbol\n",
    "# This uses QuantConnect's option data API with Greeks provided by the platform\n",
    "\n",
    "price_data = {}\n",
    "option_data_full = {}  # Store full data including Greeks\n",
    "\n",
    "for symbol in symbols:\n",
    "    try:\n",
    "        print(f\"Loading LEAP option data for {symbol}...\")\n",
    "        \n",
    "        # Get LEAP option history with Greeks from QuantConnect API\n",
    "        leap_df = get_leap_option_history(qb, symbol, start_date, end_date, \n",
    "                                          option_type='call', target_dte=365)\n",
    "        \n",
    "        if leap_df is not None and not leap_df.empty:\n",
    "            # Store prices for Markov Chain analysis\n",
    "            price_data[symbol] = leap_df['price']\n",
    "            \n",
    "            # Store full data including Greeks\n",
    "            option_data_full[symbol] = leap_df\n",
    "            \n",
    "            print(f\"  \u2713 Loaded {len(leap_df)} days of LEAP option data for {symbol}\")\n",
    "            print(f\"    - Avg DTE: {leap_df['dte'].mean():.0f} days\")\n",
    "            print(f\"    - Avg Delta: {leap_df['delta'].mean():.3f}\")\n",
    "            print(f\"    - Avg IV: {leap_df['implied_volatility'].mean():.3f}\")\n",
    "        else:\n",
    "            print(f\"  \u2717 No LEAP option data found for {symbol}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  \u2717 Error loading {symbol}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(price_data)} symbols with LEAP option data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Greeks and Option Characteristics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LEAP OPTION CHARACTERISTICS AND GREEKS (from QuantConnect API)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for symbol, opt_data in option_data_full.items():\n",
    "    print(f\"\\n{symbol}:\")\n",
    "    print(f\"  Sample Size: {len(opt_data)} trading days\")\n",
    "    print(f\"  \\nPrice Statistics:\")\n",
    "    print(f\"    Mean Option Price: ${opt_data['price'].mean():.2f}\")\n",
    "    print(f\"    Std Dev: ${opt_data['price'].std():.2f}\")\n",
    "    print(f\"    Min/Max: ${opt_data['price'].min():.2f} / ${opt_data['price'].max():.2f}\")\n",
    "    print(f\"  \\nGreeks (from QuantConnect):\")\n",
    "    print(f\"    Delta   - Mean: {opt_data['delta'].mean():.4f}, Std: {opt_data['delta'].std():.4f}\")\n",
    "    print(f\"    Gamma   - Mean: {opt_data['gamma'].mean():.4f}, Std: {opt_data['gamma'].std():.4f}\")\n",
    "    print(f\"    Vega    - Mean: {opt_data['vega'].mean():.4f}, Std: {opt_data['vega'].std():.4f}\")\n",
    "    print(f\"    Theta   - Mean: {opt_data['theta'].mean():.4f}, Std: {opt_data['theta'].std():.4f}\")\n",
    "    print(f\"    Rho     - Mean: {opt_data['rho'].mean():.4f}, Std: {opt_data['rho'].std():.4f}\")\n",
    "    print(f\"  \\nOther Characteristics:\")\n",
    "    print(f\"    Implied Volatility - Mean: {opt_data['implied_volatility'].mean():.4f}\")\n",
    "    print(f\"    Days to Expiration - Mean: {opt_data['dte'].mean():.0f}, Range: [{opt_data['dte'].min():.0f}, {opt_data['dte'].max():.0f}]\")\n",
    "    print(f\"    Avg Strike: ${opt_data['strike'].mean():.2f}\")\n",
    "    print(f\"    Avg Volume: {opt_data['volume'].mean():.0f}\")\n",
    "    print(f\"    Avg Open Interest: {opt_data['open_interest'].mean():.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Markov Chain Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Markov Chain analysis for each symbol\n",
    "results = {}\n",
    "\n",
    "for symbol, prices in price_data.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Analyzing {symbol}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Calculate daily returns\n",
    "    returns = prices.pct_change().dropna()\n",
    "    \n",
    "    # Initialize and run Markov Chain analysis\n",
    "    analyzer = MarkovChainAnalyzer(threshold=threshold)\n",
    "    backtest_results = analyzer.backtest_predictions(returns, train_ratio=train_ratio)\n",
    "    \n",
    "    results[symbol] = backtest_results\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nTraining samples: {backtest_results['n_train']}\")\n",
    "    print(f\"Testing samples: {backtest_results['n_test']}\")\n",
    "    print(f\"\\nOverall Prediction Accuracy: {backtest_results['accuracy']:.2%}\")\n",
    "    print(f\"\\nAccuracy by Current State:\")\n",
    "    print(backtest_results['accuracy_by_state'])\n",
    "    print(f\"\\nTransition Matrix:\")\n",
    "    print(backtest_results['transition_matrix'].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Transition Matrices\n",
    "n_symbols = len(results)\n",
    "fig, axes = plt.subplots(1, n_symbols, figsize=(5*n_symbols, 4))\n",
    "\n",
    "if n_symbols == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, (symbol, res) in zip(axes, results.items()):\n",
    "    tm = res['transition_matrix']\n",
    "    sns.heatmap(tm, annot=True, fmt='.2f', cmap='RdYlGn', ax=ax, vmin=0, vmax=1)\n",
    "    ax.set_title(f'{symbol} Transition Probabilities')\n",
    "    ax.set_xlabel('Next State')\n",
    "    ax.set_ylabel('Current State')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Alpha Analysis\n",
    "---\n",
    "Evaluate if Markov Chain predictions provide any predictive edge (alpha) over random chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alpha_metrics(results, threshold):\n",
    "    \"\"\"\n",
    "    Calculate alpha metrics for the Markov Chain predictions.\n",
    "    \n",
    "    Compares prediction accuracy against:\n",
    "    1. Random baseline (33.33% for 3 states)\n",
    "    2. Historical frequency baseline\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary of backtest results by symbol\n",
    "        threshold: The return threshold used for state classification\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame with alpha metrics\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    for symbol, res in results.items():\n",
    "        predictions_df = res['predictions_df']\n",
    "        \n",
    "        # Calculate historical state frequencies\n",
    "        state_freq = predictions_df['actual_state'].value_counts(normalize=True)\n",
    "        \n",
    "        # Historical frequency baseline accuracy\n",
    "        # (predicting the most common state every time)\n",
    "        baseline_accuracy = state_freq.max()\n",
    "        most_common_state = state_freq.idxmax()\n",
    "        \n",
    "        # Markov Chain accuracy\n",
    "        mc_accuracy = res['accuracy']\n",
    "        \n",
    "        # Random baseline (1/3 for 3 states)\n",
    "        random_baseline = 1/3\n",
    "        \n",
    "        # Alpha calculations\n",
    "        alpha_vs_random = mc_accuracy - random_baseline\n",
    "        alpha_vs_baseline = mc_accuracy - baseline_accuracy\n",
    "        \n",
    "        # Information Ratio (simplified)\n",
    "        # Measure consistency of predictions\n",
    "        accuracy_std = predictions_df.groupby('current_state')['correct'].std().mean()\n",
    "        ir = alpha_vs_random / accuracy_std if accuracy_std > 0 else 0\n",
    "        \n",
    "        metrics.append({\n",
    "            'Symbol': symbol,\n",
    "            'MC_Accuracy': mc_accuracy,\n",
    "            'Random_Baseline': random_baseline,\n",
    "            'Freq_Baseline': baseline_accuracy,\n",
    "            'Most_Common_State': most_common_state,\n",
    "            'Alpha_vs_Random': alpha_vs_random,\n",
    "            'Alpha_vs_Baseline': alpha_vs_baseline,\n",
    "            'Information_Ratio': ir\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate alpha metrics\n",
    "alpha_df = calculate_alpha_metrics(results, threshold)\n",
    "print(\"\\nAlpha Analysis Results:\")\n",
    "print(\"=\" * 80)\n",
    "print(alpha_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Alpha Metrics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Accuracy Comparison\n",
    "ax1 = axes[0]\n",
    "x = np.arange(len(alpha_df))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax1.bar(x - width, alpha_df['MC_Accuracy'], width, label='Markov Chain', color='blue')\n",
    "bars2 = ax1.bar(x, alpha_df['Freq_Baseline'], width, label='Frequency Baseline', color='orange')\n",
    "bars3 = ax1.bar(x + width, alpha_df['Random_Baseline'], width, label='Random (33.3%)', color='gray')\n",
    "\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Prediction Accuracy Comparison')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(alpha_df['Symbol'])\n",
    "ax1.legend()\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax1.axhline(y=0.333, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plot 2: Alpha vs Baselines\n",
    "ax2 = axes[1]\n",
    "x = np.arange(len(alpha_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax2.bar(x - width/2, alpha_df['Alpha_vs_Random'], width, label='Alpha vs Random', color='green')\n",
    "bars2 = ax2.bar(x + width/2, alpha_df['Alpha_vs_Baseline'], width, label='Alpha vs Freq Baseline', color='purple')\n",
    "\n",
    "ax2.set_ylabel('Alpha (Excess Accuracy)')\n",
    "ax2.set_title('Predictive Alpha')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(alpha_df['Symbol'])\n",
    "ax2.legend()\n",
    "ax2.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: State Persistence Analysis\n",
    "---\n",
    "Analyze if certain states tend to persist (momentum) or mean-revert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_state_persistence(results):\n",
    "    \"\"\"\n",
    "    Analyze state persistence characteristics.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary of backtest results\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame with persistence metrics\n",
    "    \"\"\"\n",
    "    persistence_metrics = []\n",
    "    \n",
    "    for symbol, res in results.items():\n",
    "        tm = res['transition_matrix']\n",
    "        \n",
    "        # Self-transition probabilities (persistence)\n",
    "        up_persistence = tm.loc['Up', 'Up']\n",
    "        down_persistence = tm.loc['Down', 'Down']\n",
    "        flat_persistence = tm.loc['Flat', 'Flat']\n",
    "        \n",
    "        # Mean reversion indicators\n",
    "        up_to_down = tm.loc['Up', 'Down']\n",
    "        down_to_up = tm.loc['Down', 'Up']\n",
    "        \n",
    "        # Momentum vs Mean Reversion score\n",
    "        # Positive = momentum, Negative = mean reversion\n",
    "        momentum_score = (up_persistence + down_persistence) / 2 - (up_to_down + down_to_up) / 2\n",
    "        \n",
    "        persistence_metrics.append({\n",
    "            'Symbol': symbol,\n",
    "            'Up_Persistence': up_persistence,\n",
    "            'Down_Persistence': down_persistence,\n",
    "            'Flat_Persistence': flat_persistence,\n",
    "            'Up_to_Down': up_to_down,\n",
    "            'Down_to_Up': down_to_up,\n",
    "            'Momentum_Score': momentum_score\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(persistence_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze state persistence\n",
    "persistence_df = analyze_state_persistence(results)\n",
    "print(\"\\nState Persistence Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"(Positive Momentum Score = trending behavior, Negative = mean reversion)\")\n",
    "print()\n",
    "print(persistence_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize persistence\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(persistence_df))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(x - width, persistence_df['Up_Persistence'], width, label='Up Persistence', color='green')\n",
    "bars2 = ax.bar(x, persistence_df['Flat_Persistence'], width, label='Flat Persistence', color='gray')\n",
    "bars3 = ax.bar(x + width, persistence_df['Down_Persistence'], width, label='Down Persistence', color='red')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_title('State Persistence Probabilities by Symbol')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(persistence_df['Symbol'])\n",
    "ax.legend()\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax.axhline(y=0.333, color='black', linestyle='--', alpha=0.5, label='Random (33.3%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Trading Strategy Simulation\n",
    "---\n",
    "Simulate a simple trading strategy based on Markov Chain predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_trading_strategy(predictions_df, returns):\n",
    "    \"\"\"\n",
    "    Simulate a trading strategy based on Markov Chain predictions.\n",
    "    \n",
    "    Strategy:\n",
    "    - Go long if predicted state is 'Up'\n",
    "    - Go short if predicted state is 'Down'\n",
    "    - Stay flat if predicted state is 'Flat'\n",
    "    \n",
    "    Args:\n",
    "        predictions_df: DataFrame with predictions\n",
    "        returns: Original returns series\n",
    "        \n",
    "    Returns:\n",
    "        dict with strategy performance metrics\n",
    "    \"\"\"\n",
    "    # Align predictions with returns\n",
    "    pred_dates = predictions_df['date'].values\n",
    "    \n",
    "    # Calculate strategy returns\n",
    "    strategy_returns = []\n",
    "    \n",
    "    for _, row in predictions_df.iterrows():\n",
    "        date = row['date']\n",
    "        predicted = row['predicted_state']\n",
    "        \n",
    "        if date in returns.index:\n",
    "            actual_return = returns.loc[date]\n",
    "            \n",
    "            if predicted == 'Up':\n",
    "                strat_return = actual_return  # Long\n",
    "            elif predicted == 'Down':\n",
    "                strat_return = -actual_return  # Short\n",
    "            else:\n",
    "                strat_return = 0  # Flat\n",
    "            \n",
    "            strategy_returns.append({\n",
    "                'date': date,\n",
    "                'predicted': predicted,\n",
    "                'actual_return': actual_return,\n",
    "                'strategy_return': strat_return\n",
    "            })\n",
    "    \n",
    "    strat_df = pd.DataFrame(strategy_returns)\n",
    "    \n",
    "    if len(strat_df) == 0:\n",
    "        return None\n",
    "    \n",
    "    strat_df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Calculate cumulative returns\n",
    "    strat_df['cum_strategy'] = (1 + strat_df['strategy_return']).cumprod() - 1\n",
    "    strat_df['cum_buy_hold'] = (1 + strat_df['actual_return']).cumprod() - 1\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    total_strategy_return = strat_df['cum_strategy'].iloc[-1]\n",
    "    total_buy_hold_return = strat_df['cum_buy_hold'].iloc[-1]\n",
    "    \n",
    "    # Annualized metrics (assuming 252 trading days)\n",
    "    n_days = len(strat_df)\n",
    "    years = n_days / 252\n",
    "    \n",
    "    annualized_strategy = (1 + total_strategy_return) ** (1/years) - 1 if years > 0 else 0\n",
    "    annualized_buy_hold = (1 + total_buy_hold_return) ** (1/years) - 1 if years > 0 else 0\n",
    "    \n",
    "    # Sharpe ratio (assuming risk-free rate = 0)\n",
    "    sharpe_strategy = strat_df['strategy_return'].mean() / strat_df['strategy_return'].std() * np.sqrt(252)\n",
    "    sharpe_buy_hold = strat_df['actual_return'].mean() / strat_df['actual_return'].std() * np.sqrt(252)\n",
    "    \n",
    "    return {\n",
    "        'returns_df': strat_df,\n",
    "        'total_strategy_return': total_strategy_return,\n",
    "        'total_buy_hold_return': total_buy_hold_return,\n",
    "        'annualized_strategy': annualized_strategy,\n",
    "        'annualized_buy_hold': annualized_buy_hold,\n",
    "        'sharpe_strategy': sharpe_strategy,\n",
    "        'sharpe_buy_hold': sharpe_buy_hold,\n",
    "        'alpha': annualized_strategy - annualized_buy_hold\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run trading strategy simulation for each symbol\n",
    "strategy_results = {}\n",
    "\n",
    "for symbol, res in results.items():\n",
    "    if symbol in price_data:\n",
    "        returns = price_data[symbol].pct_change().dropna()\n",
    "        strat_perf = simulate_trading_strategy(res['predictions_df'], returns)\n",
    "        \n",
    "        if strat_perf is not None:\n",
    "            strategy_results[symbol] = strat_perf\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"{symbol} Trading Strategy Performance\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"Total Strategy Return: {strat_perf['total_strategy_return']:.2%}\")\n",
    "            print(f\"Total Buy & Hold Return: {strat_perf['total_buy_hold_return']:.2%}\")\n",
    "            print(f\"Annualized Strategy Return: {strat_perf['annualized_strategy']:.2%}\")\n",
    "            print(f\"Annualized Buy & Hold Return: {strat_perf['annualized_buy_hold']:.2%}\")\n",
    "            print(f\"Strategy Sharpe Ratio: {strat_perf['sharpe_strategy']:.2f}\")\n",
    "            print(f\"Buy & Hold Sharpe Ratio: {strat_perf['sharpe_buy_hold']:.2f}\")\n",
    "            print(f\"Alpha (Strategy - B&H): {strat_perf['alpha']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns comparison\n",
    "n_plots = len(strategy_results)\n",
    "if n_plots > 0:\n",
    "    fig, axes = plt.subplots(2, (n_plots + 1) // 2, figsize=(14, 10))\n",
    "    axes = axes.flatten() if n_plots > 1 else [axes]\n",
    "    \n",
    "    for ax, (symbol, strat_perf) in zip(axes, strategy_results.items()):\n",
    "        df = strat_perf['returns_df']\n",
    "        \n",
    "        ax.plot(df.index, df['cum_strategy'], label='Markov Strategy', color='blue')\n",
    "        ax.plot(df.index, df['cum_buy_hold'], label='Buy & Hold', color='gray', alpha=0.7)\n",
    "        \n",
    "        ax.set_title(f'{symbol} Cumulative Returns')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Cumulative Return')\n",
    "        ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "        ax.legend()\n",
    "        ax.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for ax in axes[n_plots:]:\n",
    "        ax.set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Summary and Conclusions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary_data = []\n",
    "\n",
    "for symbol in results.keys():\n",
    "    if symbol in strategy_results:\n",
    "        alpha_row = alpha_df[alpha_df['Symbol'] == symbol].iloc[0]\n",
    "        strat_row = strategy_results[symbol]\n",
    "        persist_row = persistence_df[persistence_df['Symbol'] == symbol].iloc[0]\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Symbol': symbol,\n",
    "            'Prediction_Accuracy': alpha_row['MC_Accuracy'],\n",
    "            'Alpha_vs_Random': alpha_row['Alpha_vs_Random'],\n",
    "            'Strategy_Return': strat_row['annualized_strategy'],\n",
    "            'Buy_Hold_Return': strat_row['annualized_buy_hold'],\n",
    "            'Strategy_Alpha': strat_row['alpha'],\n",
    "            'Sharpe_Ratio': strat_row['sharpe_strategy'],\n",
    "            'Momentum_Score': persist_row['Momentum_Score']\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY: Markov Chain Analysis for LEAP Option Price Prediction\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final analysis\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "avg_accuracy = alpha_df['MC_Accuracy'].mean()\n",
    "avg_alpha_vs_random = alpha_df['Alpha_vs_Random'].mean()\n",
    "avg_strategy_alpha = summary_df['Strategy_Alpha'].mean() if len(summary_df) > 0 else 0\n",
    "\n",
    "print(f\"\\n1. PREDICTION ACCURACY:\")\n",
    "print(f\"   - Average Markov Chain Accuracy: {avg_accuracy:.2%}\")\n",
    "print(f\"   - Average Alpha vs Random: {avg_alpha_vs_random:.2%}\")\n",
    "print(f\"   - Interpretation: {'Markov Chains provide some predictive edge' if avg_alpha_vs_random > 0 else 'Limited predictive value'}\")\n",
    "\n",
    "print(f\"\\n2. TRADING STRATEGY PERFORMANCE:\")\n",
    "print(f\"   - Average Strategy Alpha: {avg_strategy_alpha:.2%}\")\n",
    "print(f\"   - Interpretation: {'Strategy outperforms buy & hold' if avg_strategy_alpha > 0 else 'Strategy underperforms buy & hold'}\")\n",
    "\n",
    "print(f\"\\n3. STATE PERSISTENCE:\")\n",
    "avg_momentum = persistence_df['Momentum_Score'].mean()\n",
    "print(f\"   - Average Momentum Score: {avg_momentum:.3f}\")\n",
    "print(f\"   - Interpretation: {'Market shows momentum tendencies' if avg_momentum > 0 else 'Market shows mean-reversion tendencies'}\")\n",
    "\n",
    "print(f\"\\n4. CONCLUSION:\")\n",
    "print(f\"   Markov Chains {'show potential' if avg_alpha_vs_random > 0.05 else 'have limited alpha'} for predicting LEAP option price movements.\")\n",
    "print(f\"   The transition probabilities reveal {'persistent' if avg_momentum > 0 else 'mean-reverting'} price behavior.\")\n",
    "print(f\"   Further analysis with actual LEAP option data and different state definitions is recommended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Notes on Implementation\n",
    "\n",
    "### Data Sources:\n",
    "1. **Option Data**: Uses QuantConnect's historical option chain data with actual LEAP option prices\n",
    "2. **Greeks**: Greeks (Delta, Gamma, Vega, Theta, Rho) are provided directly by QuantConnect API, not calculated\n",
    "3. **Implied Volatility**: IV data comes from QuantConnect's option chain\n",
    "4. **Contract Selection**: Limited to ATM LEAP options with >365 DTE to minimize data overhead\n",
    "\n",
    "### LEAP Selection Criteria:\n",
    "- **At-the-Money (ATM)**: Strike price within 5% of underlying price\n",
    "- **Days to Expiration (DTE)**: More than 365 days\n",
    "- **Target Selection**: Closest to 365 DTE in the option chain\n",
    "- **Option Type**: Call options (can be changed to puts via parameter)\n",
    "\n",
    "### Limitations of This Analysis:\n",
    "1. **Transaction Costs**: The trading simulation does not account for transaction costs, bid-ask spreads, or slippage\n",
    "2. **Liquidity**: LEAP options may have lower liquidity than near-term options, affecting execution\n",
    "3. **Rolling Strategy**: This analysis doesn't handle rolling positions as expiration approaches\n",
    "4. **Data Quality**: Historical option data quality depends on QuantConnect's data coverage for the period\n",
    "\n",
    "### Potential Improvements:\n",
    "1. Implement higher-order Markov Chains (considering multiple previous states)\n",
    "2. Add more states (e.g., Strong Up, Weak Up, Flat, Weak Down, Strong Down)\n",
    "3. Combine with Greek-based features (Delta, Gamma, Vega) for enhanced predictions\n",
    "4. Incorporate implied volatility changes as a state dimension\n",
    "5. Test different threshold values for state classification\n",
    "6. Implement walk-forward optimization for more robust backtesting\n",
    "7. Add rolling strategy that maintains LEAP positions as they approach expiration\n",
    "8. Compare call vs put LEAP options performance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}